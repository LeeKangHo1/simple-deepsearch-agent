# agents/doc_summarizer.py
"""
ë¬¸ì„œ ìš”ì•½ ì—ì´ì „íŠ¸

ê²€ìƒ‰ìœ¼ë¡œ ìˆ˜ì§‘ëœ ë¬¸ì„œë“¤ì„ ë°°ì¹˜ ë‹¨ìœ„ë¡œ ì²˜ë¦¬í•˜ì—¬ í•µì‹¬ ë‚´ìš©ë§Œ ì¶”ì¶œí•œ ìš”ì•½ë¬¸ì„ ìƒì„±í•©ë‹ˆë‹¤.
LLMì„ í™œìš©í•œ ì§€ëŠ¥ì  ìš”ì•½ê³¼ í•¨ê»˜ ì˜¤ë¥˜ ì²˜ë¦¬ ë° í’ˆì§ˆ ê²€ì¦ ê¸°ëŠ¥ì„ í¬í•¨í•©ë‹ˆë‹¤.

ì£¼ìš” ê¸°ëŠ¥:
- ë°°ì¹˜ ì²˜ë¦¬ë¥¼ í†µí•œ íš¨ìœ¨ì ì¸ ë‹¤ì¤‘ ë¬¸ì„œ ìš”ì•½
- JSON íŒŒì‹± ì‹¤íŒ¨ ì‹œ êµ¬ë¶„ì ê¸°ë°˜ í´ë°± ì²˜ë¦¬
- ë¬¸ì„œ ê¸¸ì´ì— ë”°ë¥¸ ì ì‘ì  ìš”ì•½
- í’ˆì§ˆ ê²€ì¦ ë° ì˜¤ë¥˜ ë³µêµ¬
"""

import asyncio
import json
import re
import time
import logging
from typing import List, Dict, Any, Optional, Tuple
from dataclasses import asdict

# LangChain imports
from langchain_core.prompts import ChatPromptTemplate

# í”„ë¡œì íŠ¸ ëª¨ë“ˆë“¤
from models.data_models import Document, DocumentSummary
from models.state import ResearchState, StateManager
from services.llm_service import get_llm_service, LLMResponse
from utils.text_processing import clean_text, is_valid_text, truncate_text
from utils.validators import validate_document
from utils.logger import create_agent_logger, log_execution_time

logger = logging.getLogger(__name__)
agent_logger = create_agent_logger("doc_summarizer")

class DocumentSummarizer:
    """
    ë¬¸ì„œ ìš”ì•½ ì—ì´ì „íŠ¸ í´ë˜ìŠ¤
    
    ì—¬ëŸ¬ ë¬¸ì„œë¥¼ ë°°ì¹˜ ë‹¨ìœ„ë¡œ ì²˜ë¦¬í•˜ì—¬ íš¨ìœ¨ì ìœ¼ë¡œ ìš”ì•½ì„ ìƒì„±í•©ë‹ˆë‹¤.
    LLMì˜ ì‘ë‹µ í’ˆì§ˆì„ ë³´ì¥í•˜ê¸° ìœ„í•œ ë‹¤ì–‘í•œ ì˜¤ë¥˜ ì²˜ë¦¬ ì „ëµì„ í¬í•¨í•©ë‹ˆë‹¤.
    
    ì²˜ë¦¬ íë¦„:
    1. ë¬¸ì„œ ì „ì²˜ë¦¬ ë° ìœ íš¨ì„± ê²€ì¦
    2. ë°°ì¹˜ ë‹¨ìœ„ë¡œ ê·¸ë£¹í•‘ (ê¸°ë³¸ 5ê°œì”©)
    3. LLMì„ í†µí•œ ë°°ì¹˜ ìš”ì•½ ìƒì„±
    4. JSON íŒŒì‹± ë° í´ë°± ì²˜ë¦¬
    5. í’ˆì§ˆ ê²€ì¦ ë° í›„ì²˜ë¦¬
    """
    
    def __init__(self, batch_size: int = 5, max_content_length: int = 1500, max_summary_length: int = 200):
        """
        ë¬¸ì„œ ìš”ì•½ê¸° ì´ˆê¸°í™”
        
        Args:
            batch_size: ë°°ì¹˜ í¬ê¸° (ê¸°ë³¸: 5ê°œ)
            max_content_length: ë¬¸ì„œë³„ ìµœëŒ€ ë‚´ìš© ê¸¸ì´ (ê¸°ë³¸: 1500ì)
            max_summary_length: ìš”ì•½ë¬¸ ìµœëŒ€ ê¸¸ì´ (ê¸°ë³¸: 200ì)
        """
        self.batch_size = batch_size
        self.max_content_length = max_content_length
        self.max_summary_length = max_summary_length
        self.llm_service = get_llm_service()
        
        # í†µê³„ ì¶”ì 
        self.total_documents_processed = 0
        self.total_summaries_generated = 0
        self.failed_documents = 0
        self.batch_retry_count = 0
    
    @log_execution_time
    async def summarize_documents(self, documents: List[Document], user_question: str = "") -> List[DocumentSummary]:
        """
        ë¬¸ì„œ ë¦¬ìŠ¤íŠ¸ë¥¼ ë°°ì¹˜ ì²˜ë¦¬ë¡œ ìš”ì•½
        
        Args:
            documents: ìš”ì•½í•  ë¬¸ì„œ ë¦¬ìŠ¤íŠ¸
            user_question: ì‚¬ìš©ì ì›ë³¸ ì§ˆë¬¸ (ìš”ì•½ ë°©í–¥ì„± ì œê³µìš©)
            
        Returns:
            List[DocumentSummary]: ìƒì„±ëœ ë¬¸ì„œ ìš”ì•½ ë¦¬ìŠ¤íŠ¸
        """
        if not documents:
            logger.warning("ìš”ì•½í•  ë¬¸ì„œê°€ ì—†ìŠµë‹ˆë‹¤.")
            return []
        
        agent_logger.start_step(f"ë¬¸ì„œ ìš”ì•½ ì‹œì‘ ({len(documents)}ê°œ ë¬¸ì„œ)")
        
        try:
            # 1ë‹¨ê³„: ë¬¸ì„œ ì „ì²˜ë¦¬ ë° í•„í„°ë§
            valid_documents = self._preprocess_documents(documents)
            
            if not valid_documents:
                agent_logger.end_step("ë¬¸ì„œ ì „ì²˜ë¦¬", False, "ìœ íš¨í•œ ë¬¸ì„œê°€ ì—†ìŒ")
                return []
            
            # 2ë‹¨ê³„: ë°°ì¹˜ ì²˜ë¦¬ë¡œ ìš”ì•½ ìƒì„±
            summaries = await self._process_documents_in_batches(valid_documents, user_question)
            
            # 3ë‹¨ê³„: í†µê³„ ì—…ë°ì´íŠ¸
            self.total_documents_processed += len(valid_documents)
            self.total_summaries_generated += len(summaries)
            
            agent_logger.end_step(
                "ë¬¸ì„œ ìš”ì•½ ì™„ë£Œ", 
                True, 
                f"{len(summaries)}/{len(valid_documents)} ìš”ì•½ ìƒì„± ì™„ë£Œ"
            )
            
            return summaries
            
        except Exception as e:
            agent_logger.end_step("ë¬¸ì„œ ìš”ì•½", False, f"ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
            logger.error(f"ë¬¸ì„œ ìš”ì•½ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            return []
    
    def _preprocess_documents(self, documents: List[Document]) -> List[Document]:
        """
        ë¬¸ì„œ ì „ì²˜ë¦¬ ë° ìœ íš¨ì„± ê²€ì¦
        
        Args:
            documents: ì „ì²˜ë¦¬í•  ë¬¸ì„œ ë¦¬ìŠ¤íŠ¸
            
        Returns:
            List[Document]: ìœ íš¨ì„± ê²€ì¦ì„ í†µê³¼í•œ ë¬¸ì„œ ë¦¬ìŠ¤íŠ¸
        """
        valid_documents = []
        filtered_count = 0
        
        for doc in documents:
            try:
                # ë¬¸ì„œ ìœ íš¨ì„± ê²€ì¦
                is_valid, errors = validate_document(doc)
                if not is_valid:
                    logger.debug(f"ë¬¸ì„œ ê²€ì¦ ì‹¤íŒ¨ '{doc.title}': {errors}")
                    filtered_count += 1
                    continue
                
                # ë‚´ìš© ê¸¸ì´ ê²€ì¦ (ë„ˆë¬´ ì§§ê±°ë‚˜ ë¹ˆ ë¬¸ì„œ ì œì™¸)
                cleaned_content = clean_text(doc.content)
                if len(cleaned_content.strip()) < 20:  # 20ì ë¯¸ë§Œì€ ì œì™¸
                    logger.debug(f"ë¬¸ì„œ ë‚´ìš©ì´ ë„ˆë¬´ ì§§ìŒ: '{doc.title}' ({len(cleaned_content)}ì)")
                    filtered_count += 1
                    continue
                
                # ë¬¸ì„œ ë‚´ìš© ê¸¸ì´ ì¡°ì • (1500ìë¡œ ì œí•œ)
                if len(doc.content) > self.max_content_length:
                    doc.content = doc.content[:self.max_content_length]
                
                valid_documents.append(doc)
                
            except Exception as e:
                logger.warning(f"ë¬¸ì„œ ì „ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {doc.title} - {e}")
                filtered_count += 1
        
        if filtered_count > 0:
            logger.info(f"ë¬¸ì„œ ì „ì²˜ë¦¬ ì™„ë£Œ: {len(valid_documents)}ê°œ ìœ íš¨, {filtered_count}ê°œ í•„í„°ë§ë¨")
        
        return valid_documents
    
    async def _process_documents_in_batches(self, documents: List[Document], user_question: str) -> List[DocumentSummary]:
        """
        ë¬¸ì„œë“¤ì„ ë°°ì¹˜ ë‹¨ìœ„ë¡œ ì²˜ë¦¬í•˜ì—¬ ìš”ì•½ ìƒì„±
        
        Args:
            documents: ì²˜ë¦¬í•  ë¬¸ì„œ ë¦¬ìŠ¤íŠ¸
            user_question: ì‚¬ìš©ì ì§ˆë¬¸
            
        Returns:
            List[DocumentSummary]: ìƒì„±ëœ ìš”ì•½ ë¦¬ìŠ¤íŠ¸
        """
        all_summaries = []
        
        # ë¬¸ì„œë“¤ì„ ë°°ì¹˜ í¬ê¸°ë§Œí¼ ê·¸ë£¹í•‘
        batches = [documents[i:i + self.batch_size] for i in range(0, len(documents), self.batch_size)]
        
        logger.info(f"ë°°ì¹˜ ì²˜ë¦¬ ì‹œì‘: {len(batches)}ê°œ ë°°ì¹˜, ë°°ì¹˜ë‹¹ ìµœëŒ€ {self.batch_size}ê°œ ë¬¸ì„œ")
        
        for batch_idx, batch in enumerate(batches):
            try:
                logger.debug(f"ë°°ì¹˜ {batch_idx + 1}/{len(batches)} ì²˜ë¦¬ ì¤‘... ({len(batch)}ê°œ ë¬¸ì„œ)")
                
                # ë°°ì¹˜ ìš”ì•½ ì‹œë„
                batch_summaries = await self._summarize_batch(batch, user_question, batch_idx)
                all_summaries.extend(batch_summaries)
                
            except Exception as e:
                logger.error(f"ë°°ì¹˜ {batch_idx + 1} ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
                # ì‹¤íŒ¨í•œ ë°°ì¹˜ëŠ” ì›ë³¸ ë‚´ìš© ì¼ë¶€ë¥¼ ì‚¬ìš©í•œ ê¸°ë³¸ ìš”ì•½ìœ¼ë¡œ ëŒ€ì²´
                fallback_summaries = self._create_fallback_summaries(batch)
                all_summaries.extend(fallback_summaries)
        
        return all_summaries
    
    async def _summarize_batch(self, batch: List[Document], user_question: str, batch_idx: int) -> List[DocumentSummary]:
        """
        ë‹¨ì¼ ë°°ì¹˜ì˜ ë¬¸ì„œë“¤ì„ ìš”ì•½
        
        Args:
            batch: ìš”ì•½í•  ë¬¸ì„œ ë°°ì¹˜
            user_question: ì‚¬ìš©ì ì§ˆë¬¸
            batch_idx: ë°°ì¹˜ ì¸ë±ìŠ¤
            
        Returns:
            List[DocumentSummary]: ë°°ì¹˜ ìš”ì•½ ê²°ê³¼
        """
        max_retries = 1  # ì¬ì‹œë„ 1ë²ˆë§Œ
        
        for attempt in range(max_retries + 1):
            try:
                # LLMì„ í†µí•œ ë°°ì¹˜ ìš”ì•½ ìƒì„±
                llm_response = await self._generate_batch_summary(batch, user_question)
                
                if not llm_response.success:
                    if attempt < max_retries:
                        logger.warning(f"ë°°ì¹˜ {batch_idx + 1} LLM í˜¸ì¶œ ì‹¤íŒ¨, ì¬ì‹œë„ ì¤‘...")
                        self.batch_retry_count += 1
                        continue
                    else:
                        raise Exception(f"LLM í˜¸ì¶œ ì‹¤íŒ¨: {llm_response.error_message}")
                
                # ì‘ë‹µ íŒŒì‹± ë° ìš”ì•½ ê°ì²´ ìƒì„±
                summaries = self._parse_batch_response(llm_response.content, batch)
                
                if len(summaries) > 0:
                    logger.debug(f"ë°°ì¹˜ {batch_idx + 1} ì²˜ë¦¬ ì™„ë£Œ: {len(summaries)}/{len(batch)} ìš”ì•½ ìƒì„±")
                    return summaries
                else:
                    if attempt < max_retries:
                        logger.warning(f"ë°°ì¹˜ {batch_idx + 1} íŒŒì‹± ì‹¤íŒ¨, ì¬ì‹œë„ ì¤‘...")
                        continue
                    else:
                        raise Exception("ìš”ì•½ íŒŒì‹±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
                        
            except Exception as e:
                if attempt < max_retries:
                    logger.warning(f"ë°°ì¹˜ {batch_idx + 1} ì²˜ë¦¬ ì‹¤íŒ¨ (ì‹œë„ {attempt + 1}), ì¬ì‹œë„: {e}")
                    await asyncio.sleep(1)  # ì¬ì‹œë„ ì „ ëŒ€ê¸°
                    continue
                else:
                    logger.error(f"ë°°ì¹˜ {batch_idx + 1} ìµœì¢… ì‹¤íŒ¨: {e}")
                    # í´ë°±: ì„±ê³µí•œ ë¶€ë¶„ë§Œ ì‚¬ìš©í•˜ê³  ë‚˜ë¨¸ì§€ëŠ” ì›ë³¸ ë‚´ìš© ì¼ë¶€ ì‚¬ìš©
                    return self._create_fallback_summaries(batch)
        
        return []
    
    async def _generate_batch_summary(self, batch: List[Document], user_question: str) -> LLMResponse:
        """
        LLMì„ í†µí•´ ë°°ì¹˜ ìš”ì•½ ìƒì„±
        
        Args:
            batch: ìš”ì•½í•  ë¬¸ì„œ ë°°ì¹˜
            user_question: ì‚¬ìš©ì ì§ˆë¬¸
            
        Returns:
            LLMResponse: LLM ì‘ë‹µ
        """
        # ë°°ì¹˜ìš© í”„ë¡¬í”„íŠ¸ ë‚´ìš© êµ¬ì„±
        batch_content = ""
        for i, doc in enumerate(batch, 1):
            # ë¬¸ì„œ ë‚´ìš© ì •ì œ ë° ê¸¸ì´ ì œí•œ
            cleaned_content = clean_text(doc.content)
            truncated_content = cleaned_content[:self.max_content_length]
            
            batch_content += f"=== ë¬¸ì„œ {i} ===\n"
            batch_content += f"ì œëª©: {doc.title}\n"
            batch_content += f"ì¶œì²˜: {doc.url}\n"
            batch_content += f"ë‚´ìš©: {truncated_content}\n\n"
        
        # ì‚¬ìš©ì ì§ˆë¬¸ ì»¨í…ìŠ¤íŠ¸ ì¶”ê°€
        question_context = f"\n\nì‚¬ìš©ì ì§ˆë¬¸: {user_question}" if user_question.strip() else ""
        
        # ë°°ì¹˜ ìš”ì•½ í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿
        prompt_template = ChatPromptTemplate.from_messages([
            ("system", f"""ë‹¹ì‹ ì€ ë¬¸ì„œ ìš”ì•½ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì£¼ì–´ì§„ {len(batch)}ê°œ ë¬¸ì„œë¥¼ ê°ê° {self.max_summary_length}ì ì´ë‚´ë¡œ ìš”ì•½í•´ì£¼ì„¸ìš”.

ìš”ì•½ ê·œì¹™:
1. ê° ë¬¸ì„œì˜ í•µì‹¬ ë‚´ìš©ê³¼ ì£¼ìš” í¬ì¸íŠ¸ë§Œ í¬í•¨
2. ê°ê´€ì ì´ê³  ì •í™•í•œ ì •ë³´ë§Œ ì¶”ì¶œ
3. ê°œì¸ì ì¸ ì˜ê²¬ì´ë‚˜ ì¶”ì¸¡ì€ ì œì™¸  
4. ëª…í™•í•˜ê³  ê°„ê²°í•œ ë¬¸ì¥ìœ¼ë¡œ ì‘ì„±
5. ê° ìš”ì•½ì€ {self.max_summary_length}ìë¥¼ ì´ˆê³¼í•˜ì§€ ë§ ê²ƒ
6. ì‚¬ìš©ì ì§ˆë¬¸ê³¼ ê´€ë ¨ëœ ë‚´ìš©ì— ìš°ì„ ìˆœìœ„ë¥¼ ë‘˜ ê²ƒ{question_context}

ì¶œë ¥ í˜•ì‹ - ê° ìš”ì•½ì„ êµ¬ë¶„ìë¡œ ë¶„ë¦¬:
===SUMMARY_1===
ì²« ë²ˆì§¸ ë¬¸ì„œì˜ ìš”ì•½ ë‚´ìš©
===SUMMARY_2===  
ë‘ ë²ˆì§¸ ë¬¸ì„œì˜ ìš”ì•½ ë‚´ìš©
===SUMMARY_3===
ì„¸ ë²ˆì§¸ ë¬¸ì„œì˜ ìš”ì•½ ë‚´ìš©

(ë¬¸ì„œ ê°œìˆ˜ë§Œí¼ ë°˜ë³µ)"""),
            ("user", "{batch_content}")
        ])
        
        return await self.llm_service._call_llm(
            prompt_template=prompt_template,
            input_variables={"batch_content": batch_content},
            agent_type="doc_summarizer",
            output_parser=self.llm_service.str_parser,
            expected_type=str
        )
    
    def _parse_batch_response(self, response_content: str, batch: List[Document]) -> List[DocumentSummary]:
        """
        ë°°ì¹˜ ì‘ë‹µì„ íŒŒì‹±í•˜ì—¬ DocumentSummary ê°ì²´ ìƒì„±
        
        Args:
            response_content: LLM ì‘ë‹µ ë‚´ìš©
            batch: ì›ë³¸ ë¬¸ì„œ ë°°ì¹˜
            
        Returns:
            List[DocumentSummary]: íŒŒì‹±ëœ ìš”ì•½ ê°ì²´ ë¦¬ìŠ¤íŠ¸
        """
        summaries = []
        
        try:
            # 1ë‹¨ê³„: JSON íŒŒì‹± ì‹œë„ (í˜¹ì‹œ JSON í˜•íƒœë¡œ ë°˜í™˜ëœ ê²½ìš°)
            try:
                json_data = json.loads(response_content)
                if isinstance(json_data, list):
                    summary_texts = json_data
                else:
                    raise ValueError("JSONì´ ë°°ì—´ í˜•íƒœê°€ ì•„ë‹˜")
            except (json.JSONDecodeError, ValueError):
                # 2ë‹¨ê³„: êµ¬ë¶„ì ê¸°ë°˜ íŒŒì‹± (í´ë°± ì „ëµ)
                summary_texts = self._parse_with_separators(response_content)
            
            # 3ë‹¨ê³„: DocumentSummary ê°ì²´ ìƒì„±
            for i, doc in enumerate(batch):
                if i < len(summary_texts):
                    # ì„±ê³µì ìœ¼ë¡œ íŒŒì‹±ëœ ìš”ì•½ ì‚¬ìš©
                    summary_text = summary_texts[i].strip()
                    
                    # ìš”ì•½ë¬¸ ìœ íš¨ì„± ê²€ì¦
                    if len(summary_text) >= 10 and is_valid_text(summary_text):
                        summary = DocumentSummary(
                            document_hash=doc.content_hash,
                            summary=summary_text,
                            key_points=self._extract_key_points(summary_text),
                            confidence_score=0.8,  # ë°°ì¹˜ ì²˜ë¦¬ ê¸°ë³¸ ì‹ ë¢°ë„
                            word_count=len(summary_text)
                        )
                        summaries.append(summary)
                    else:
                        # ìœ íš¨í•˜ì§€ ì•Šì€ ìš”ì•½ì¸ ê²½ìš° í´ë°±
                        fallback_summary = self._create_single_fallback_summary(doc)
                        summaries.append(fallback_summary)
                        self.failed_documents += 1
                else:
                    # ìš”ì•½ì´ ë¶€ì¡±í•œ ê²½ìš° í´ë°± (ì›ë³¸ ë‚´ìš© ì¼ë¶€ ì‚¬ìš©)
                    fallback_summary = self._create_single_fallback_summary(doc)
                    summaries.append(fallback_summary)
                    self.failed_documents += 1
            
            logger.debug(f"ë°°ì¹˜ íŒŒì‹± ì™„ë£Œ: {len(summaries)} ìš”ì•½ ìƒì„±")
            return summaries
            
        except Exception as e:
            logger.error(f"ë°°ì¹˜ ì‘ë‹µ íŒŒì‹± ì‹¤íŒ¨: {e}")
            # ì „ì²´ ì‹¤íŒ¨ ì‹œ ëª¨ë“  ë¬¸ì„œì— ëŒ€í•´ í´ë°± ìš”ì•½ ìƒì„±
            return self._create_fallback_summaries(batch)
    
    def _parse_with_separators(self, content: str) -> List[str]:
        """
        êµ¬ë¶„ìë¥¼ ì‚¬ìš©í•˜ì—¬ ì‘ë‹µ ë‚´ìš© íŒŒì‹±
        
        Args:
            content: íŒŒì‹±í•  ì‘ë‹µ ë‚´ìš©
            
        Returns:
            List[str]: ë¶„ë¦¬ëœ ìš”ì•½ í…ìŠ¤íŠ¸ ë¦¬ìŠ¤íŠ¸
        """
        summaries = []
        
        try:
            # ===SUMMARY_N=== íŒ¨í„´ìœ¼ë¡œ ë¶„ë¦¬
            pattern = r'===SUMMARY_\d+===(.*?)(?====SUMMARY_\d+===|$)'
            matches = re.findall(pattern, content, re.DOTALL)
            
            if matches:
                summaries = [match.strip() for match in matches]
                logger.debug(f"êµ¬ë¶„ì íŒŒì‹± ì„±ê³µ: {len(summaries)}ê°œ ìš”ì•½ ì¶”ì¶œ")
            else:
                # ëŒ€ì•ˆ êµ¬ë¶„ì ì‹œë„: === ë‹¨ë…
                parts = re.split(r'={3,}', content)
                summaries = [part.strip() for part in parts if part.strip() and len(part.strip()) > 10]
                logger.debug(f"ëŒ€ì•ˆ êµ¬ë¶„ì íŒŒì‹±: {len(summaries)}ê°œ ìš”ì•½ ì¶”ì¶œ")
            
            return summaries
            
        except Exception as e:
            logger.error(f"êµ¬ë¶„ì íŒŒì‹± ì‹¤íŒ¨: {e}")
            return []
    
    def _extract_key_points(self, summary_text: str) -> List[str]:
        """
        ìš”ì•½ë¬¸ì—ì„œ í•µì‹¬ í¬ì¸íŠ¸ ì¶”ì¶œ
        
        Args:
            summary_text: ìš”ì•½ í…ìŠ¤íŠ¸
            
        Returns:
            List[str]: í•µì‹¬ í¬ì¸íŠ¸ ë¦¬ìŠ¤íŠ¸
        """
        # ê°„ë‹¨í•œ ë¬¸ì¥ ë¶„ë¦¬ë¡œ í•µì‹¬ í¬ì¸íŠ¸ ì¶”ì¶œ
        sentences = re.split(r'[.!?]\s+', summary_text)
        key_points = []
        
        for sentence in sentences:
            sentence = sentence.strip()
            if len(sentence) > 15:  # ì˜ë¯¸ ìˆëŠ” ê¸¸ì´ì˜ ë¬¸ì¥ë§Œ
                key_points.append(sentence)
        
        return key_points[:3]  # ìµœëŒ€ 3ê°œê¹Œì§€
    
    def _create_fallback_summaries(self, batch: List[Document]) -> List[DocumentSummary]:
        """
        í´ë°± ìš”ì•½ ìƒì„± (ë°°ì¹˜ ì „ì²´ ì‹¤íŒ¨ ì‹œ)
        
        Args:
            batch: ì‹¤íŒ¨í•œ ë°°ì¹˜ ë¬¸ì„œë“¤
            
        Returns:
            List[DocumentSummary]: í´ë°± ìš”ì•½ ë¦¬ìŠ¤íŠ¸
        """
        fallback_summaries = []
        
        for doc in batch:
            fallback_summary = self._create_single_fallback_summary(doc)
            fallback_summaries.append(fallback_summary)
        
        logger.info(f"í´ë°± ìš”ì•½ ìƒì„± ì™„ë£Œ: {len(fallback_summaries)}ê°œ")
        return fallback_summaries
    
    def _create_single_fallback_summary(self, doc: Document) -> DocumentSummary:
        """
        ë‹¨ì¼ ë¬¸ì„œì— ëŒ€í•œ í´ë°± ìš”ì•½ ìƒì„±
        
        Args:
            doc: í´ë°± ìš”ì•½ì„ ìƒì„±í•  ë¬¸ì„œ
            
        Returns:
            DocumentSummary: í´ë°± ìš”ì•½ ê°ì²´
        """
        # ì›ë³¸ ë‚´ìš©ì˜ ì²˜ìŒ ë¶€ë¶„ì„ ìš”ì•½ìœ¼ë¡œ ì‚¬ìš©
        cleaned_content = clean_text(doc.content)
        fallback_text = truncate_text(cleaned_content, self.max_summary_length, "...")
        
        return DocumentSummary(
            document_hash=doc.content_hash,
            summary=fallback_text,
            key_points=[fallback_text],
            confidence_score=0.3,  # ë‚®ì€ ì‹ ë¢°ë„ í‘œì‹œ
            word_count=len(fallback_text)
        )
    
    def get_processing_stats(self) -> Dict[str, Any]:
        """
        ì²˜ë¦¬ í†µê³„ ì •ë³´ ë°˜í™˜
        
        Returns:
            Dict[str, Any]: í†µê³„ ì •ë³´
        """
        success_rate = 0.0
        if self.total_documents_processed > 0:
            success_rate = (self.total_summaries_generated - self.failed_documents) / self.total_documents_processed * 100
        
        return {
            "total_documents_processed": self.total_documents_processed,
            "total_summaries_generated": self.total_summaries_generated,
            "failed_documents": self.failed_documents,
            "batch_retry_count": self.batch_retry_count,
            "success_rate_percent": round(success_rate, 2),
            "batch_size": self.batch_size,
            "max_content_length": self.max_content_length,
            "max_summary_length": self.max_summary_length
        }


# LangGraph ë…¸ë“œ í•¨ìˆ˜
async def summarize_documents_node(state: ResearchState) -> ResearchState:
    """
    ë¬¸ì„œ ìš”ì•½ LangGraph ë…¸ë“œ
    
    Stateì˜ documentsë¥¼ ë°›ì•„ì„œ ìš”ì•½ì„ ìƒì„±í•˜ê³  summariesì— ì €ì¥í•©ë‹ˆë‹¤.
    
    Args:
        state: í˜„ì¬ ì—°êµ¬ ìƒíƒœ
        
    Returns:
        ResearchState: ìš”ì•½ì´ ì¶”ê°€ëœ ì—…ë°ì´íŠ¸ëœ ìƒíƒœ
    """
    logger.info("=== ë¬¸ì„œ ìš”ì•½ ë…¸ë“œ ì‹œì‘ ===")
    
    try:
        # í˜„ì¬ ë‹¨ê³„ ì„¤ì •
        state = StateManager.set_step(state, "summarizing", "ğŸ“ ë¬¸ì„œ ìš”ì•½ ì¤‘...")
        
        # ë¬¸ì„œ í™•ì¸
        if not state.get("documents"):
            error_msg = "ìš”ì•½í•  ë¬¸ì„œê°€ ì—†ìŠµë‹ˆë‹¤."
            logger.warning(error_msg)
            return StateManager.set_error(state, error_msg)
        
        # Document ê°ì²´ ìƒì„±
        documents = []
        for doc_dict in state["documents"]:
            try:
                doc = Document(
                    title=doc_dict.get("title", ""),
                    url=doc_dict.get("url", ""),
                    content=doc_dict.get("content", ""),
                    source=doc_dict.get("source", "unknown")
                )
                documents.append(doc)
            except Exception as e:
                logger.warning(f"ë¬¸ì„œ ê°ì²´ ìƒì„± ì‹¤íŒ¨: {e}")
                continue
        
        if not documents:
            error_msg = "ìœ íš¨í•œ ë¬¸ì„œ ê°ì²´ë¥¼ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
            logger.error(error_msg)
            return StateManager.set_error(state, error_msg)
        
        # ë¬¸ì„œ ìš”ì•½ê¸° ìƒì„± ë° ì‹¤í–‰
        summarizer = DocumentSummarizer()
        summaries = await summarizer.summarize_documents(
            documents=documents,
            user_question=state.get("user_input", "")
        )
        
        if not summaries:
            # ë¬¸ì„œê°€ ì—†ì„ ë•Œ ê¸°ë³¸ ìš”ì•½ ìƒì„±
            logger.warning("ë¬¸ì„œ ìš”ì•½ì´ ì—†ì–´ ê¸°ë³¸ ìš”ì•½ì„ ìƒì„±í•©ë‹ˆë‹¤.")
            user_question = state.get("user_input", "")
            fallback_summary = f"{user_question}ì— ëŒ€í•œ ì •ë³´ë¥¼ ì°¾ëŠ” ì¤‘ì…ë‹ˆë‹¤. í˜„ì¬ ê´€ë ¨ ë¬¸ì„œë¥¼ ìˆ˜ì§‘í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤."
            summary_texts = [fallback_summary]
        else:
            # ìš”ì•½ ê²°ê³¼ë¥¼ ë¬¸ìì—´ ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜í•˜ì—¬ ìƒíƒœì— ì €ì¥
            summary_texts = [summary.summary for summary in summaries]
        
        # ìš”ì•½ ê²°ê³¼ë¥¼ ë¬¸ìì—´ ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜í•˜ì—¬ ìƒíƒœì— ì €ì¥
        summary_texts = [summary.summary for summary in summaries]
        
        # ìƒíƒœ ì—…ë°ì´íŠ¸
        new_state = state.copy()
        new_state["summaries"] = summary_texts
        
        # ì²˜ë¦¬ í†µê³„ ë¡œê¹…
        stats = summarizer.get_processing_stats()
        logger.info(f"ë¬¸ì„œ ìš”ì•½ ì™„ë£Œ: {stats}")
        
        new_state = StateManager.add_log(
            new_state, 
            f"ğŸ“ ë¬¸ì„œ ìš”ì•½ ì™„ë£Œ: {len(summary_texts)}ê°œ ìš”ì•½ ìƒì„± (ì„±ê³µë¥ : {stats['success_rate_percent']}%)"
        )
        
        logger.info("=== ë¬¸ì„œ ìš”ì•½ ë…¸ë“œ ì™„ë£Œ ===")
        return new_state
        
    except Exception as e:
        error_msg = f"ë¬¸ì„œ ìš”ì•½ ë…¸ë“œì—ì„œ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"
        logger.error(error_msg)
        return StateManager.set_error(state, error_msg)


# ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ë“¤
def create_document_summarizer(batch_size: int = 5) -> DocumentSummarizer:
    """
    ë¬¸ì„œ ìš”ì•½ê¸° ì¸ìŠ¤í„´ìŠ¤ ìƒì„± í—¬í¼ í•¨ìˆ˜
    
    Args:
        batch_size: ë°°ì¹˜ í¬ê¸°
        
    Returns:
        DocumentSummarizer: ì„¤ì •ëœ ë¬¸ì„œ ìš”ì•½ê¸° ì¸ìŠ¤í„´ìŠ¤
    """
    return DocumentSummarizer(batch_size=batch_size)

