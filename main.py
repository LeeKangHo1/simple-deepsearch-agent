# main.py
import streamlit as st
import time
import asyncio
from typing import List, Dict, Optional
import logging

# í”„ë¡œì íŠ¸ ëª¨ë“ˆë“¤
from workflows.research_workflow import execute_research, get_workflow_status
from config.settings import settings
from utils.logger import setup_logging, get_logger

# ë¡œê¹… ì„¤ì •
setup_logging()
logger = get_logger("streamlit_app")

# Streamlit í˜ì´ì§€ ì„¤ì •
st.set_page_config(
    page_title="Deep Research Chatbot",
    page_icon="ğŸ”",
    layout="wide",
    initial_sidebar_state="collapsed"
)

# ì»¤ìŠ¤í…€ CSS ìŠ¤íƒ€ì¼ë§
st.markdown("""
<style>
    .main-header {
        text-align: center;
        padding: 1rem 0;
        margin-bottom: 2rem;
    }
    
    .status-container {
        background-color: #f0f2f6;
        padding: 1rem;
        border-radius: 10px;
        margin: 1rem 0;
        border-left: 4px solid #1f77b4;
    }
    
    .status-message {
        font-size: 14px;
        color: #666;
        margin: 0.5rem 0;
    }
    
    .result-container {
        background-color: white;
        padding: 1.5rem;
        border-radius: 10px;
        margin: 1rem 0;
        box-shadow: 0 2px 4px rgba(0,0,0,0.1);
    }
    
    .user-question {
        background-color: #e3f2fd;
        padding: 1rem;
        border-radius: 8px;
        margin-bottom: 1rem;
        border-left: 4px solid #2196f3;
    }
    
    .processing-indicator {
        display: flex;
        align-items: center;
        gap: 10px;
    }
    
    .spinner {
        width: 20px;
        height: 20px;
        border: 2px solid #f3f3f3;
        border-top: 2px solid #1f77b4;
        border-radius: 50%;
        animation: spin 1s linear infinite;
    }
    
    @keyframes spin {
        0% { transform: rotate(0deg); }
        100% { transform: rotate(360deg); }
    }
</style>
""", unsafe_allow_html=True)

def init_session_state():
    """ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”"""
    if 'processing' not in st.session_state:
        st.session_state.processing = False
    if 'current_step' not in st.session_state:
        st.session_state.current_step = ""
    if 'status_messages' not in st.session_state:
        st.session_state.status_messages = []
    if 'result' not in st.session_state:
        st.session_state.result = ""
    if 'user_question' not in st.session_state:
        st.session_state.user_question = ""

def add_status_message(message: str):
    """ìƒíƒœ ë©”ì‹œì§€ ì¶”ê°€"""
    timestamp = time.strftime("%H:%M:%S")
    st.session_state.status_messages.append(f"[{timestamp}] {message}")

async def execute_research_workflow(query: str):
    """ì‹¤ì œ LangGraph ì›Œí¬í”Œë¡œìš° ì‹¤í–‰"""
    
    def progress_callback(step: str, message: str):
        """ì§„í–‰ ìƒíƒœ ì½œë°± í•¨ìˆ˜"""
        add_status_message(message)
        st.session_state.current_step = step
    
    try:
        # ì›Œí¬í”Œë¡œìš° ì‹¤í–‰
        result = await execute_research(query, progress_callback)
        
        # ë””ë²„ê¹…ì„ ìœ„í•œ ë¡œê¹… ì¶”ê°€
        logger.info(f"Workflow result: success={result.get('success')}, answer_length={len(result.get('markdown_answer', ''))}")
        
        if result["success"]:
            markdown_answer = result["markdown_answer"]
            if markdown_answer and markdown_answer.strip():
                st.session_state.result = markdown_answer
                st.session_state.execution_stats = result["stats"]
                add_status_message(f"âœ… ë¦¬ì„œì¹˜ ì™„ë£Œ! (ì‹¤í–‰ ì‹œê°„: {result['execution_time']:.1f}ì´ˆ)")
            else:
                # ë‹µë³€ì´ ë¹„ì–´ìˆëŠ” ê²½ìš°
                st.session_state.result = f"# ê²€ìƒ‰ ê²°ê³¼ ì—†ìŒ\n\n'{query}'ì— ëŒ€í•œ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\n\në‹¤ë¥¸ í‚¤ì›Œë“œë¡œ ë‹¤ì‹œ ì‹œë„í•´ë³´ì„¸ìš”."
                add_status_message("âš ï¸ ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
        else:
            error_msg = result.get("error_message", "ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.")
            st.session_state.result = f"# ì˜¤ë¥˜ ë°œìƒ\n\n{error_msg}"
            add_status_message(f"âŒ ë¦¬ì„œì¹˜ ì‹¤íŒ¨: {error_msg}")
            logger.error(f"Research workflow failed: {error_msg}")
    
    except Exception as e:
        error_msg = f"ì›Œí¬í”Œë¡œìš° ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"
        st.session_state.result = f"# ì‹œìŠ¤í…œ ì˜¤ë¥˜\n\n{error_msg}"
        add_status_message(f"âŒ ì‹œìŠ¤í…œ ì˜¤ë¥˜: {error_msg}")
        logger.error(f"Workflow execution error: {e}", exc_info=True)

def main():
    """ë©”ì¸ ì• í”Œë¦¬ì¼€ì´ì…˜"""
    init_session_state()
    
    # í—¤ë”
    st.markdown('<div class="main-header">', unsafe_allow_html=True)
    st.title("ğŸ” Deep Research Chatbot")
    st.markdown("**ë‹¤ê°ë„ ì‹¬ì¸µ ì¡°ì‚¬ë¥¼ í†µí•œ ì‹ ë¢°í•  ìˆ˜ ìˆëŠ” ì •ë³´ ì œê³µ**")
    st.markdown('</div>', unsafe_allow_html=True)
    
    # ì§ˆë¬¸ ì…ë ¥ ì„¹ì…˜
    st.markdown("### ğŸ’­ ì§ˆë¬¸ì„ ì…ë ¥í•´ì£¼ì„¸ìš”")
    
    with st.form("research_form"):
        user_input = st.text_area(
            label="ì—°êµ¬í•˜ê³  ì‹¶ì€ ì£¼ì œë‚˜ ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”",
            placeholder="ì˜ˆ: ì˜¤í”ˆì†ŒìŠ¤ LLM íŠ¸ë Œë“œ ì•Œë ¤ì¤˜",
            height=100,
            label_visibility="collapsed"
        )
        
        col1, col2, col3 = st.columns([1, 2, 1])
        with col2:
            submitted = st.form_submit_button(
                "ğŸš€ ì‹¬ì¸µ ì¡°ì‚¬ ì‹œì‘",
                use_container_width=True,
                disabled=st.session_state.processing
            )
    
    # í”„ë¡œì„¸ì‹± ì‹œì‘
    if submitted and user_input.strip():
        st.session_state.processing = True
        st.session_state.user_question = user_input.strip()
        st.session_state.status_messages = []
        st.session_state.result = ""
        st.rerun()
    
    # ì§„í–‰ ìƒíƒœ í‘œì‹œ
    if st.session_state.processing:
        st.markdown("### ğŸ“Š ì§„í–‰ ìƒíƒœ")
        
        # ìƒíƒœ ì»¨í…Œì´ë„ˆ
        status_container = st.empty()
        
        with status_container.container():
            st.markdown('<div class="status-container">', unsafe_allow_html=True)
            
            # í˜„ì¬ ì§„í–‰ ë‹¨ê³„ í‘œì‹œ
            if st.session_state.current_step:
                st.markdown(f"""
                <div class="processing-indicator">
                    <div class="spinner"></div>
                    <strong>{st.session_state.current_step}</strong>
                </div>
                """, unsafe_allow_html=True)
            
            # ì§„í–‰ ìƒíƒœ ë©”ì‹œì§€ë“¤
            if st.session_state.status_messages:
                st.markdown("**ì§„í–‰ ê¸°ë¡:**")
                for msg in st.session_state.status_messages[-5:]:  # ìµœê·¼ 5ê°œë§Œ í‘œì‹œ
                    st.markdown(f'<div class="status-message">âœ“ {msg}</div>', unsafe_allow_html=True)
            
            st.markdown('</div>', unsafe_allow_html=True)
        
        # ì‹¤ì œ ì›Œí¬í”Œë¡œìš° ì‹¤í–‰
        if not st.session_state.result:
            # ë¹„ë™ê¸° ì›Œí¬í”Œë¡œìš° ì‹¤í–‰
            try:
                asyncio.run(execute_research_workflow(st.session_state.user_question))
            except Exception as e:
                logger.error(f"Failed to run research workflow: {e}")
                st.session_state.result = f"# ì‹¤í–‰ ì˜¤ë¥˜\n\nì›Œí¬í”Œë¡œìš° ì‹¤í–‰ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤: {str(e)}"
                add_status_message(f"âŒ ì‹¤í–‰ ì‹¤íŒ¨: {str(e)}")
            
            # ì™„ë£Œ ì²˜ë¦¬
            st.session_state.processing = False
            st.session_state.current_step = "ì™„ë£Œ!"
            st.rerun()
    
    # ê²°ê³¼ í‘œì‹œ
    if st.session_state.result and st.session_state.user_question:
        st.markdown("### ğŸ“‹ ì¡°ì‚¬ ê²°ê³¼")
        
        # ì‚¬ìš©ì ì§ˆë¬¸ í‘œì‹œ
        st.markdown(f"""
        <div class="user-question">
            <strong>ğŸ“ ì§ˆë¬¸:</strong> {st.session_state.user_question}
        </div>
        """, unsafe_allow_html=True)
        
        # ê²°ê³¼ í‘œì‹œ
        st.markdown('<div class="result-container">', unsafe_allow_html=True)
        st.markdown(st.session_state.result)
        st.markdown('</div>', unsafe_allow_html=True)
        
        # ìƒˆ ê²€ìƒ‰ ë²„íŠ¼
        col1, col2, col3 = st.columns([1, 2, 1])
        with col2:
            if st.button("ğŸ”„ ìƒˆë¡œìš´ ì§ˆë¬¸í•˜ê¸°", use_container_width=True):
                # ìƒíƒœ ì´ˆê¸°í™”
                st.session_state.processing = False
                st.session_state.current_step = ""
                st.session_state.status_messages = []
                st.session_state.result = ""
                st.session_state.user_question = ""
                st.rerun()
    
    # ì‚¬ì´ë“œë°” ì •ë³´ (ì„ íƒì‚¬í•­)
    with st.sidebar:
        st.markdown("### â„¹ï¸ ì‹œìŠ¤í…œ ì •ë³´")
        st.markdown("""
        **Deep Research Chatbot**
        - ë©€í‹° ì—ì´ì „íŠ¸ ê¸°ë°˜ ì‹¬ì¸µ ì¡°ì‚¬
        - ìë™ ê²€ì¦ ë° ì¬ê²€ìƒ‰ ì‹œìŠ¤í…œ
        - ì‹ ë¢°í•  ìˆ˜ ìˆëŠ” ì¶œì²˜ ê¸°ë°˜ ì‘ë‹µ
        
        **ê¸°ëŠ¥:**
        - ì§ˆë¬¸ ìë™ í™•ì¥
        - ë³‘ë ¬ ì›¹ ê²€ìƒ‰ (DuckDuckGo + Tavily)
        - ìŠ¤ë§ˆíŠ¸ ë¬¸ì„œ ìš”ì•½
        - í’ˆì§ˆ ê²€ì¦ ë° ì¬ê²€ìƒ‰
        """)
        
        st.markdown("---")
        st.markdown("**ì„¤ì • ì •ë³´:**")
        st.markdown(f"- LLM ì œê³µì: {settings.LLM_PROVIDER}")
        st.markdown(f"- ì±„íŒ… ëª¨ë¸: {settings.chat_model}")
        st.markdown(f"- ìµœëŒ€ ê²€ìƒ‰ ê²°ê³¼: {settings.MAX_SEARCH_RESULTS}")
        st.markdown(f"- LangSmith: {'í™œì„±í™”' if settings.LANGCHAIN_TRACING_V2 else 'ë¹„í™œì„±í™”'}")
        
        # ì‹¤í–‰ í†µê³„ í‘œì‹œ (ìˆëŠ” ê²½ìš°)
        if hasattr(st.session_state, 'execution_stats') and st.session_state.execution_stats:
            st.markdown("---")
            st.markdown("**ì‹¤í–‰ í†µê³„:**")
            stats = st.session_state.execution_stats
            st.markdown(f"- í•˜ìœ„ ì¿¼ë¦¬: {stats.get('sub_queries_count', 0)}ê°œ")
            st.markdown(f"- ìˆ˜ì§‘ ë¬¸ì„œ: {stats.get('documents_count', 0)}ê°œ")
            st.markdown(f"- ì¸ì‚¬ì´íŠ¸: {stats.get('insights_count', 0)}ê°œ")
            st.markdown(f"- ì¬ì‹œë„: {stats.get('retry_count', 0)}íšŒ")
        
        st.markdown("---")
        st.markdown("**ê°œë°œ ìƒíƒœ:** MVP")
        st.markdown("**ê¸°ìˆ  ìŠ¤íƒ:** LangChain + LangGraph + Streamlit")

if __name__ == "__main__":
    main()